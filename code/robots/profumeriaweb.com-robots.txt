User-agent: *
 
# # Crawl-delay parameter: the number of seconds you want to wait between successful requests to the same server.
# # Set a crawl rate, if your server's traffic problems. Please note that Google ignore crawl-delay setting in Robots.txt. You can set up this in Google Webmaster tool
Crawl-delay: 5
 
# # Do not index the page Magento admin
Disallow: / gestione_backend_negoziopw /
 
# # Do not index the general technical Magento directory
Disallow: / app /
Disallow: / dev /
Disallow: / downloader /
Disallow: / errors /
Disallow: / includes /
Disallow: / lib /
Disallow: / pkginfo /
Disallow: / shell /
Disallow: / var /
 
# # Do not index the shared files Magento
Disallow: / api.php
Disallow: / cron.php
Disallow: / cron.sh
Disallow: / get.php
Disallow: / m_test_search_speed.php
Disallow: / info.txt
 
# # Do not index the page subcategories that are sorted or filtered.
Disallow: / *? Dir *
Disallow: / *? Dir = desc
Disallow: / *? Dir = asc
Disallow: / *? Limit = all
Disallow: / *? Mode *
 
# # Do not index the link from the session ID
Disallow: / *? SID =
 
# # Do not index the page checkout and user account
Disallow: / checkout /
Disallow: / checkout / onepage /
Disallow: / customer /
Disallow: / customer / account /
Disallow: / customer / account / login /
 
# # Do not index the search page and CEO, non-optimized link categories
Disallow: / catalogsearch /
Disallow: / catalog / product_compare /
Disallow: / catalog / category / view /
Disallow: / catalog / product / view /

# # Do not index the general technical directories and files on a server
Disallow: / opcache_clean.php


User-agent: Screaming Frog SEO Spider
Crawl-delay: 10
Disallow:
